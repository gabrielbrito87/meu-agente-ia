import streamlit as st
import google.generativeai as genai

# Configura√ß√£o visual
st.set_page_config(page_title="Agente de Qualidade", layout="wide")
st.title("ü§ñ Assistente e Avaliador da Equipe")

# 1. Configura√ß√£o da IA
genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
model = genai.GenerativeModel('gemini-1.5-flash')

# 2. Carregar Base de Conhecimento
try:
    with open("base.txt", "r", encoding="utf-8") as f:
        conhecimento = f.read()
    st.sidebar.success(f"‚úÖ Base carregada: {len(conhecimento)} caracteres")
except:
    st.sidebar.error("‚ùå Arquivo base.txt n√£o encontrado!")
    conhecimento = ""

# 3. Upload de arquivos para avalia√ß√£o (A fun√ß√£o que voc√™ queria!)
st.sidebar.divider()
st.sidebar.header("Avaliar Documento")
arquivo_subido = st.sidebar.file_uploader("Suba um arquivo para confer√™ncia", type=["txt", "pdf", "docx"])

conteudo_do_arquivo = ""
if arquivo_subido:
    conteudo_do_arquivo = arquivo_subido.read().decode("utf-8", errors="ignore")
    st.sidebar.info("Arquivo pronto para an√°lise.")

# 4. Interface do Chat
if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if prompt := st.chat_input("Ex: Este arquivo est√° correto? / Como fa√ßo para..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        # O SEGREDO: Instru√ß√£o detalhada (System Prompt)
        contexto_sistema = f"""
        Voc√™ √© um Assistente Colaborativo de elite. Sua miss√£o √© ajudar a equipe com base nestas regras:
        ---
        {conhecimento}
        ---
        REGRAS DE OURO:
        1. Se o usu√°rio enviar um arquivo para an√°lise (abaixo), compare-o com a base de conhecimento e diga o que est√° errado.
        2. Se a resposta n√£o estiver na base, diga educadamente que n√£o possui essa informa√ß√£o.
        3. Seja direto e profissional.

        ARQUIVO PARA ANALISAR AGORA (se houver): {conteudo_do_arquivo}
        """
        
        try:
            # Enviamos a instru√ß√£o pesada e a pergunta do usu√°rio
            response = model.generate_content([contexto_sistema, prompt])
            
            st.markdown(response.text)
            st.session_state.messages.append({"role": "assistant", "content": response.text})
        except Exception as e:
            st.error(f"Erro ao processar: {e}")
